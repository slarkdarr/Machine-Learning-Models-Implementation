{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "f21PRg_RKh0W"
      },
      "outputs": [],
      "source": [
        "# Import modules\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ZiWfMZQfMkVd"
      },
      "outputs": [],
      "source": [
        "# Fungsi-fungsi aktivasi\n",
        "def linear(x):\n",
        "  return x\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def relu(x):\n",
        "  return np.maximum(0, x)\n",
        "\n",
        "def softmax(x):\n",
        "  e = np.exp(x)\n",
        "  return e / np.sum(e)\n",
        "\n",
        "activation_function = {\n",
        "    \"Linear\": linear,\n",
        "    \"Sigmoid\": sigmoid,\n",
        "    \"ReLU\": relu,\n",
        "    \"Softmax\": softmax,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "igZEzwshQzRh"
      },
      "outputs": [],
      "source": [
        "class Layer():\n",
        "  def __init__(self, weight, bias, activation):\n",
        "    if activation not in ['Linear', 'Sigmoid', 'ReLU', 'Softmax']:\n",
        "          raise NotImplementedError(\"Layer activation `%s` is not implemented.\" \n",
        "                                      % activation)\n",
        "    self.weight = weight\n",
        "    self.bias = bias\n",
        "    self.activation = activation\n",
        "\n",
        "  def forward_propagation(self, input):\n",
        "    input_T = input.T\n",
        "    result = np.dot(self.weight, input_T) + self.bias\n",
        "    return activation_function[self.activation](result)\n",
        "\n",
        "class NeuralNetwork():\n",
        "  def __init__(self):\n",
        "    self.layers = []\n",
        "  \n",
        "  def summary(self):\n",
        "    print(\"Jumlah layer: \", len(self.layers))\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      print(\"============================================================\")\n",
        "      print('Layer {} (Activation: \"{}\", Units: {})'\n",
        "      .format(i+1, layer.activation, len(layer.weight)))\n",
        "      \n",
        "      print(\"Weight:\")\n",
        "      print(np.array(layer.weight))\n",
        "      \n",
        "      print(\"Bias:\")\n",
        "      print(np.array(layer.bias))\n",
        "    print(\"============================================================\")\n",
        "\n",
        "  def add(self, layer):\n",
        "    self.layers.append(layer)\n",
        "  \n",
        "  def predict(self, input):\n",
        "    arr = np.array(input)\n",
        "    if arr.ndim == 1:\n",
        "      instance = arr\n",
        "      instance_res = instance\n",
        "      for layer in self.layers:\n",
        "        instance_res = layer.forward_propagation(instance_res)\n",
        "      return instance_res\n",
        "      \n",
        "    batch = arr\n",
        "    batch_res = []\n",
        "    for instance in batch:\n",
        "      instance_res = instance\n",
        "      for layer in self.layers:\n",
        "        instance_res = layer.forward_propagation(instance_res)\n",
        "      \n",
        "      batch_res.append(instance_res)\n",
        "    \n",
        "    return batch_res\n",
        "        \n",
        "  def load_file(self, filename):\n",
        "    '''\n",
        "    File format\n",
        "    <depth>\n",
        "    <units> <activation function>\n",
        "    <weight0> \n",
        "    <bias0>\n",
        "    '''\n",
        "    with open(filename, 'r') as file:\n",
        "      depth = int(file.readline().strip())\n",
        "      for i in range (depth):\n",
        "        line = file.readline().strip().split()\n",
        "        unit = int(line[0])\n",
        "        activation = line[1]\n",
        "\n",
        "        # Weight Matrice\n",
        "        weight = []\n",
        "        for j in range(unit):\n",
        "          weight.append(list(map(float, file.readline().strip().split())))\n",
        "\n",
        "        # Bias Matrice\n",
        "        bias = list(map(float, file.readline().strip().split()))\n",
        "        \n",
        "\n",
        "        # Add layer\n",
        "        layer = Layer(weight, bias, activation)\n",
        "        self.add(layer)\n",
        "      \n",
        "      # End of file\n",
        "    # Close file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "JFyzxJGRM6Hs"
      },
      "outputs": [],
      "source": [
        "# XOR Sigmoid Model dan XOR Relu-Linear Model\n",
        "model1 = NeuralNetwork()\n",
        "model2 = NeuralNetwork()\n",
        "filename1 = 'xor_sigmoid.txt'\n",
        "filename2 = 'xor_relu_linear.txt'\n",
        "\n",
        "data = [[0, 0],\n",
        "        [0, 1],\n",
        "        [1, 0],\n",
        "        [1, 1]]\n",
        "        \n",
        "model1.load_file(filename1)\n",
        "model2.load_file(filename2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OLLk7YS54k6T",
        "outputId": "0822ce3f-32ee-414d-89da-f260d37f6e14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah layer:  2\n",
            "============================================================\n",
            "Layer 1 (Activation: \"Sigmoid\", Units: 2)\n",
            "Weight:\n",
            "[[ 20.  20.]\n",
            " [-20. -20.]]\n",
            "Bias:\n",
            "[-10.  30.]\n",
            "============================================================\n",
            "Layer 2 (Activation: \"Sigmoid\", Units: 1)\n",
            "Weight:\n",
            "[[20. 20.]]\n",
            "Bias:\n",
            "[-30.]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "model1.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aWu3mrSR2pZ7",
        "outputId": "252a1106-3009-492d-b2eb-f5eca411559b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah layer:  2\n",
            "============================================================\n",
            "Layer 1 (Activation: \"ReLU\", Units: 2)\n",
            "Weight:\n",
            "[[1. 1.]\n",
            " [1. 1.]]\n",
            "Bias:\n",
            "[ 0. -1.]\n",
            "============================================================\n",
            "Layer 2 (Activation: \"Linear\", Units: 1)\n",
            "Weight:\n",
            "[[ 1. -2.]]\n",
            "Bias:\n",
            "[0.]\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFNv1jR-Gu7E",
        "outputId": "0f10f618-cf4c-4af8-e0ba-8bac03a8a570"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[array([4.54391049e-05]),\n",
              " array([0.99995452]),\n",
              " array([0.99995452]),\n",
              " array([4.54391049e-05])]"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.predict(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-96PEuauUa3U",
        "outputId": "00822c71-7ebb-4373-b970-66a4a21198db"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([4.54391049e-05])"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model1.predict([0, 0])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "TubesA_NIM.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
